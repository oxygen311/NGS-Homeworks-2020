{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spades.py --only-error-correction --pe1-1 data/4/ecoli_400K_err_1.fastq.gz --pe1-2 data/4/ecoli_400K_err_2.fastq.gz -o data/4/corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.01 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.09 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.03 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index data/4/MG1655-K12.first400K.fasta\n",
      "[main] Real time: 0.144 sec; CPU: 0.151 sec\n"
     ]
    }
   ],
   "source": [
    "!bwa index data/4/MG1655-K12.first400K.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!bwa mem data/4/MG1655-K12.first400K.fasta data/4/ecoli_400K_err_1.fastq.00.0_0.cor.fastq.gz data/4/ecoli_400K_err_2.fastq.00.0_0.cor.fastq.gz > data/4/corrected_alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2716054 + 0 in total (QC-passed reads + QC-failed reads)\r\n",
      "0 + 0 secondary\r\n",
      "0 + 0 supplementary\r\n",
      "0 + 0 duplicates\r\n",
      "2715944 + 0 mapped (100.00% : N/A)\r\n",
      "2716054 + 0 paired in sequencing\r\n",
      "1358027 + 0 read1\r\n",
      "1358027 + 0 read2\r\n",
      "2714586 + 0 properly paired (99.95% : N/A)\r\n",
      "2715876 + 0 with itself and mate mapped\r\n",
      "68 + 0 singletons (0.00% : N/A)\r\n",
      "0 + 0 with mate mapped to a different chr\r\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\r\n"
     ]
    }
   ],
   "source": [
    "!samtools flagstat data/4/corrected_alignment.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!bwa mem data/4/MG1655-K12.first400K.fasta data/4/ecoli_400K_err_1.fastq.gz data/4/ecoli_400K_err_2.fastq.gz > data/4/original_alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2763204 + 0 in total (QC-passed reads + QC-failed reads)\r\n",
      "0 + 0 secondary\r\n",
      "0 + 0 supplementary\r\n",
      "0 + 0 duplicates\r\n",
      "2762617 + 0 mapped (99.98% : N/A)\r\n",
      "2763204 + 0 paired in sequencing\r\n",
      "1381602 + 0 read1\r\n",
      "1381602 + 0 read2\r\n",
      "2760820 + 0 properly paired (99.91% : N/A)\r\n",
      "2762132 + 0 with itself and mate mapped\r\n",
      "485 + 0 singletons (0.02% : N/A)\r\n",
      "0 + 0 with mate mapped to a different chr\r\n",
      "0 + 0 with mate mapped to a different chr (mapQ>=5)\r\n"
     ]
    }
   ],
   "source": [
    "!samtools flagstat data/4/original_alignment.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_reference_pos_to_read_nuleotide(read):\n",
    "    read_seq = read.query_sequence\n",
    "    pairs = read.get_aligned_pairs(matches_only=False)\n",
    "    \n",
    "    return dict([(ref_pos, read_seq[read_pos] if read_pos is not None else None) for read_pos, ref_pos in pairs])\n",
    "    \n",
    "def get_dict_from_reference_pos_to_reference_nucleotide(read):\n",
    "    pairs = read.get_aligned_pairs(matches_only=False, with_seq=True)\n",
    "    \n",
    "    return dict([(ref_pos, ref_n) for read_pos, ref_pos, ref_n in pairs])\n",
    "\n",
    "def count_corrections(corr_sam_file, orig_sam_file):\n",
    "    corr_sam = pysam.AlignmentFile(corr_sam_file, \"r\")\n",
    "    orig_sam = pysam.AlignmentFile(orig_sam_file, \"r\")\n",
    "    \n",
    "    ans = np.zeros((2,3), dtype=int)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            corr_read, orig_read = next(corr_sam), next(orig_sam)\n",
    "            \n",
    "            if corr_read.is_unmapped or corr_read.is_supplementary: continue\n",
    "            if orig_read.is_unmapped or orig_read.is_supplementary: continue\n",
    "            \n",
    "            # count those reads as absent?\n",
    "            while corr_read.query_name != orig_read.query_name:\n",
    "                orig_read = next(orig_sam)\n",
    "                \n",
    "            ref_positions_orig = orig_read.get_reference_positions()\n",
    "            ref_positions_corr = corr_read.get_reference_positions()   \n",
    "            \n",
    "            mapped_orig = get_dict_from_reference_pos_to_read_nuleotide(orig_read)\n",
    "            mapped_corr = get_dict_from_reference_pos_to_read_nuleotide(corr_read)\n",
    "            \n",
    "            ref_pos_to_nucleotide = get_dict_from_reference_pos_to_reference_nucleotide(orig_read)\n",
    "            \n",
    "            for ref_pos in set(mapped_orig.keys()) & set(mapped_corr.keys()):\n",
    "                ref_base = ref_pos_to_nucleotide[ref_pos]\n",
    "                orig_base = mapped_orig[ref_pos]\n",
    "                corr_base = mapped_corr[ref_pos]\n",
    "                \n",
    "                if corr_base == 'N':\n",
    "                    ans[int(orig_base == ref_base)][2] += 1\n",
    "                    continue\n",
    "                        \n",
    "                if orig_base != ref_base:\n",
    "                    ans[0][int(corr_base == ref_base)] += 1\n",
    "                else:\n",
    "                    ans[1][int(corr_base == orig_base)] += 1   \n",
    "        \n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "    return ans\n",
    "\n",
    "arr = count_corrections('data/4/corrected_alignment.sam', 'data/4/original_alignment.sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error in corrected reads</th>\n",
       "      <th>Correct base in corrected reads</th>\n",
       "      <th>Base is absent in corrected reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Error in raw data</td>\n",
       "      <td>Undetected error: 1058063</td>\n",
       "      <td>Detected &amp; corrected error: 182</td>\n",
       "      <td>Detected and removed error: 326925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Correct base in raw data</td>\n",
       "      <td>Falsely corrected error: 545</td>\n",
       "      <td>Correctly unmodified base: 246936100</td>\n",
       "      <td>Incorrectly removed base: 380383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Error in corrected reads  \\\n",
       "Error in raw data            Undetected error: 1058063   \n",
       "Correct base in raw data  Falsely corrected error: 545   \n",
       "\n",
       "                               Correct base in corrected reads  \\\n",
       "Error in raw data              Detected & corrected error: 182   \n",
       "Correct base in raw data  Correctly unmodified base: 246936100   \n",
       "\n",
       "                           Base is absent in corrected reads  \n",
       "Error in raw data         Detected and removed error: 326925  \n",
       "Correct base in raw data    Incorrectly removed base: 380383  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_ans_human_readable(ans):\n",
    "    ans_str = np.array(ans, dtype=str)\n",
    "    ans_annotation = np.array([['Undetected error: ', 'Detected & corrected error: ', 'Detected and removed error: '], \n",
    "                               ['Falsely corrected error: ', 'Correctly unmodified base: ', 'Incorrectly removed base: ']])\n",
    "\n",
    "    ans_concated = np.core.defchararray.add(ans_annotation, ans_str)\n",
    "    df = pd.DataFrame(ans_concated, columns=[\"Error in corrected reads\", \"Correct base in corrected reads\", \"Base is absent in corrected reads\"])\n",
    "    df.set_index([['Error in raw data', 'Correct base in raw data']], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = make_ans_human_readable(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Краткое изложение метода\n",
    "Выравниваем исходные и скорретированые риды на референс и идём по обоим выравниваниям сразу сразу итератором.\n",
    "Попутно скипая выкинутые риды, которых нет в скорректированных (их я считать как absent не стал).\n",
    "Когда получили два рида, непонятно насколько одинаково и хорошо они выравнились, поэтому чтобы не писать сосисочный код делаем следующие: <br>\n",
    "1) Для каждого рида строим словарь типа 'позиция в референсе' -> 'нуклеотид в риде' <br>\n",
    "2) Строим такой же словарь для рефенса, 'позиция в референсе' -> 'нуклеотид в референсе' <br>\n",
    "3) Пересекаем множество ключей словарей и в цикле проходимся по всем тройкам баз <br>\n",
    "Получив соответствующие базы, уже достаточно написать несколько ифоф, чтобы посчитать ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
